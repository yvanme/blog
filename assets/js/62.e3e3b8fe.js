(window.webpackJsonp=window.webpackJsonp||[]).push([[62],{420:function(s,a,t){"use strict";t.r(a);var e=t(44),r=Object(e.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"centos7下spark环境搭建-集群"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#centos7下spark环境搭建-集群"}},[s._v("#")]),s._v(" Centos7下Spark环境搭建（集群）")]),s._v(" "),t("h2",{attrs:{id:"介绍"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#介绍"}},[s._v("#")]),s._v(" 介绍")]),s._v(" "),t("p",[s._v("[TOC]")]),s._v(" "),t("p",[t("strong",[s._v("安装环境：")])]),s._v(" "),t("p",[t("strong",[s._v("system：CentOS7")])]),s._v(" "),t("p",[t("strong",[s._v("spark:spark-2.4.3-bin-hadoop2.7")])]),s._v(" "),t("h2",{attrs:{id:"spark安装"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#spark安装"}},[s._v("#")]),s._v(" Spark安装")]),s._v(" "),t("ol",[t("li",[t("p",[s._v("解压spark包")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("tar")]),s._v(" -zvxf spark-2.4.3-bin-hadoop2.7.tgz\n")])])])]),s._v(" "),t("li",[t("p",[s._v("配置环境变量")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#修改/etc下profile文件，加入以下配置并使用source /etc/profile命令使之生效")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#Spark")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SPARK_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/spark-2.4.3-bin-hadoop2.7\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[t("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("PATH")])]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token environment constant"}},[s._v("$PATH")]),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token variable"}},[s._v("${SPARK_HOME}")]),s._v("/bin\n")])])])]),s._v(" "),t("li",[t("p",[s._v("配置Spark")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("进入 ${SPARK_HOME}/conf 目录")])]),s._v(" "),t("li",[t("p",[s._v("执行如下命令")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("cp spark-env.sh.template spark-env.sh\ncp slaves.template slaves\n")])])])]),s._v(" "),t("li",[t("p",[s._v("slaves")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("master\nslave1\nslave2\n")])])])]),s._v(" "),t("li",[t("p",[s._v("spark-env.sh")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#配置jdk")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("JAVA_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/jdk1.8.0_221\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#配置hadoop 配置文件目录")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HADOOP_CONF_DIR")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/hadoop-3.1.2/etc/hadoop\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#配置hadoop 根目录")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token builtin class-name"}},[s._v("export")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("HADOOP_HOME")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/hadoop-3.1.2 \n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spark master webui 端口，默认是8080，跟tomcat 冲突")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SPARK_MASTER_WEBUI_PORT")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("8888")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#配置spark HA 配置")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SPARK_DAEMON_JAVA_OPTS")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"-Dspark.deploy.recoveryMode=ZOOKEEPER\n-Dspark.deploy.zookeeper.url=master:2181,slave1:2181,slave2:2181\n-Dspark.deploy.zookeeper.dir=/myspark"')]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spark 配置文件目录")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SPARK_CONF_DIR")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/spark-2.4.3-bin-hadoop2.7/conf\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spark 日志目录")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SPARK_LOG_DIR")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/spark-2.4.3-bin-hadoop2.7/logs\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#spark 进程ip 文件保存位置")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("SPARK_PID_DIR")]),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("/apps/spark-2.4.3-bin-hadoop2.7/logs\n")])])])]),s._v(" "),t("li",[t("p",[s._v("创建相应目录")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("runRemoteCmd.sh "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v('"mkdir -p /apps/spark-2.4.3-bin-hadoop2.7/logs"')]),s._v(" all\n")])])])]),s._v(" "),t("li",[t("p",[s._v("拷贝hdfs 配置文件到spark 目录")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[t("span",{pre:!0,attrs:{class:"token function"}},[s._v("cp")]),s._v(" core-site.xml /apps/spark-2.4.3-bin-hadoop2.7/conf/\n"),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("cp")]),s._v(" hdfs-site.xml /apps/spark-2.4.3-bin-hadoop2.7/conf/\n")])])])]),s._v(" "),t("li",[t("p",[s._v("拷贝到各个节点")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("deploy.sh /apps/spark-2.4.3-bin-hadoop2.7 /apps/ slave\n")])])])])])]),s._v(" "),t("li",[t("p",[s._v("启动Spark")]),s._v(" "),t("ul",[t("li",[t("p",[s._v("进入${SPARK_HOME}/sbin 目录，执行如下命令")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("sbin/start-all.sh\n")])])])])])]),s._v(" "),t("li",[t("p",[s._v("浏览器访问")]),s._v(" "),t("div",{staticClass:"language- extra-class"},[t("pre",{pre:!0,attrs:{class:"language-text"}},[t("code",[s._v("http://master:8888/\n")])])])]),s._v(" "),t("li",[t("p",[s._v("提交yarn任务")]),s._v(" "),t("div",{staticClass:"language-shell extra-class"},[t("pre",{pre:!0,attrs:{class:"language-shell"}},[t("code",[s._v("./spark-submit --class com.loong.MyJavaWordCount --master "),t("span",{pre:!0,attrs:{class:"token function"}},[s._v("yarn")]),s._v(" --deploy-mode cluster /apps/wordcount.jar  /user/hive/warehouse/stu/stu.txt /out\n")])])])])])])}),[],!1,null,null,null);a.default=r.exports}}]);